---
title: "Model"
author: "Eduardo Yuki Yada"
geometry: margin=1cm
output: 
  pdf_document:
    template: latex-template.tex
params:
  outcome_column: readmission_30d
---

# Imports

```{r warning=F, message=F}
library(tidyverse)
library(yaml)
```

# Loading data

```{r}
load('../dataset/processed_data.RData') 
load('../dataset/processed_dictionary.RData') 

columns_list <- yaml.load_file("./auxiliar/columns_list.yaml")

outcome_column <- params$outcome_column
```

# Filtering eligible pacients

```{r}
df = df %>%
  filter(death_hospitalar == 0)
```

# Choosing features

```{r}
eligible_columns = df_names %>%
  filter(momento.aquisicao == 'AdmissÃ£o t0') %>%
  .$variable.name

features = eligible_columns %>%
  base::intersect(c(columns_list$categorical_columns, columns_list$numerical_columns))
```

# Train test split

```{r}
smp_size <- 0.5 * dim(df)[1]
set.seed(42)

df[columns_list$outcome_columns] <- lapply(df[columns_list$outcome_columns], factor)

train_ind <- base::sample(seq_len(nrow(df)), size = smp_size)
df_train <- df[train_ind, ] %>% dplyr::select(all_of(c(features, outcome_column)))
df_test <- df[-train_ind, ] %>% dplyr::select(all_of(c(features, outcome_column)))
```

# Model

```{r}
library(tidymodels)
library(usemodels) 

use_xgboost(sprintf('%s ~ .', outcome_column) %>% as.formula,
            data = df_train)
```

```{r}
xgboost_recipe <- 
  recipe(formula = sprintf('%s ~ .', outcome_column) %>% as.formula,
         data = df_train) %>% 
  step_string2factor(one_of("sex", "race", "education_level", "patient_state", 
    "underlying_heart_disease", "heart_disease", "nyha_basal", "hypertension", 
    "prior_mi", "heart_failure", "af", "cardiac_arrest", "transplant", "valvopathy", 
    "endocardites", "diabetes", "renal_failure", "hemodialysis", "stroke", 
    "copd", "cancer", "surgery_count", "procedure_type_1", "reop_type_1", "cied_final_1", 
    "death_intraop_1", "dialysis_hosp", "icu_hosp", "admission_pre_t0_180d", 
    "icu_t0", "dialysis_t0", "icu_post_t0", "disch_outcomes_t0", 
    "ventilacao_mecanica")) %>% 
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% 
  step_zv(all_predictors()) 

xgboost_spec <- 
  boost_tree(trees = 100) %>% 
  set_mode("classification") %>% 
  set_engine("xgboost") 

xgboost_workflow <- 
  workflow() %>% 
  add_recipe(xgboost_recipe) %>% 
  add_model(xgboost_spec) 
```

```{r}
xgb_fit <- xgboost_workflow %>% 
  fit(df_train)
```
```{r}
library(pROC)

test_predictions_prob <- predict(xgb_fit, new_data = df_test, type = "prob") %>% 
  rename_at(vars(starts_with(".pred_")), ~str_remove(., ".pred_")) %>%
  .$`1`

pROC_obj <- roc(df_test[[outcome_column]], test_predictions_prob,
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)

sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
## Warning in plot.ci.se(sens.ci, type = "shape", col = "lightblue"): Low
## definition shape.
plot(sens.ci, type="bars")
```

```{r}
library(caret)

test_predictions_class <- predict(xgb_fit, new_data = df_test, type = "class") %>% 
  rename_at(vars(starts_with(".pred_")), ~str_remove(., ".pred_")) %>%
  .$class

conf_matrix = table(test_predictions_class, df_test[[outcome_column]])

confusionMatrix(conf_matrix)
```

