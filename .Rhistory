t_df <- data.table::transpose(df)
colnames(t_df) <- rownames(df)
rownames(t_df) <- colnames(df)
t_df <- t_df %>%
tibble::rownames_to_column(.data = .) %>%
tibble::as_tibble(.)
return(t_df)
}
header.true <- function(df) {
names(df) <- as.character(unlist(df[1,]))
df[-1,]
}
data <- data_raw %>% select(-all_of(remove_columns))
fviz_nbclust(data, kmeans, method = "wss") +
geom_vline(xintercept = K, linetype = 2)
km.res <- kmeans(data, K, iter.max = 50, nstart = 20)
tibble(Cluster = seq(1:K),
`Sum of Squares` = km.res$withinss) %>%
niceFormatting(caption = "Within-cluster sum of squares")
evaluate_cluster(km.res$cluster)
knitr::opts_chunk$set(
echo = F,
warning = F
)
library(tidyverse)
library(readxl)
library(factoextra)
library(scales)
library(kableExtra)
data_raw <- read_excel('dataset/Planilha_dados_Clusterização_CD_RC_enviada_alterado.xlsx')
data_raw <- data_raw %>% mutate(group = paste0('Group ', group))
remove_columns <- c('record_id', 'group')
K <- 4
paste_matrix <- function(...,sep = " ", collapse = NULL) {
n <- max(sapply(list(...),nrow))
p <- max(sapply(list(...),ncol))
matrix(paste(...,sep = sep,collapse = collapse),n,p)
}
percent <- function(x) paste0("(", lapply(x, as.character), "%)")
addpercentage <- function(df) {
x <- df %>%
prop.table(margin = 1) %>%
addmargins(FUN = list(Total = sum), quiet = TRUE) %>%
round(2) * 100
x[nrow(x),] <- " "
x[-(nrow(x)),] <- lapply(x[-(nrow(x)), ], percent)
y <- matrix(x, nrow = nrow(df) + 1)
df <- df %>%
addmargins(FUN = list(Total = sum), quiet = TRUE)
df_final <- paste_matrix(df, y)
rownames(df_final) <- rownames(df)
colnames(df_final) <- colnames(df)
return(df_final)
}
evaluate_cluster <- function(clusters) {
data <- cbind(data, cluster = clusters) %>%
mutate(cluster = factor(paste0('Cluster ', cluster)))
table(data_raw$group, data$cluster) %>%
addpercentage %>%
as.data.frame %>%
rownames_to_column(var = 'Group') %>%
kbl(align = "c", booktabs = T, digits = 2, format = 'latex',
caption = 'Distribuição dos grupos nos clusters', label = 1) %>%
row_spec(K, hline_after = T) %>%
column_spec(K + 1, border_right = T) %>%
collapse_rows(1, latex_hline = "none") %>%
add_header_above(c(' ' = 1,
setNames(K, 'Cluster'))) %>%
kable_styling(latex_options = c("HOLD_position", "repeat_header")) %>%
print
table(data$cluster, data_raw$group) %>%
addpercentage %>%
as.data.frame %>%
rownames_to_column(var = 'Cluster') %>%
kbl(align = "c", booktabs = T, digits = 2, format = 'latex',
caption = 'Distribuição dos clusters nos grupos', label = 1) %>%
row_spec(K, hline_after = T) %>%
column_spec(K + 1, border_right = T) %>%
collapse_rows(1, latex_hline = "none") %>%
add_header_above(c(' ' = 1,
setNames(K, 'Group'))) %>%
kable_styling(latex_options = c("HOLD_position", "repeat_header")) %>%
print
data %>%
group_by(cluster) %>%
summarise(across(everything(), list(mean = mean))) %>%
ungroup %>%
mutate(across(where(is.numeric), round, 2)) %>%
transpose_df %>%
header.true %>%
mutate(Variable = gsub("\\_.*","", cluster)) %>%
select(Variable, `Cluster 1`, `Cluster 2`, `Cluster 3`, `Cluster 4`) %>%
niceFormatting(caption = 'Médias das variáveis por cluster') %>%
print
}
niceFormatting = function(df, caption="", digits = 2, font_size = NULL, label = 1){
df %>%
kbl(booktabs = T, longtable = T, caption = caption,
digits = digits, format = "latex", label = label) %>%
kable_styling(font_size = font_size,
latex_options = c("striped", "HOLD_position", "repeat_header"))
}
transpose_df <- function(df) {
t_df <- data.table::transpose(df)
colnames(t_df) <- rownames(df)
rownames(t_df) <- colnames(df)
t_df <- t_df %>%
tibble::rownames_to_column(.data = .) %>%
tibble::as_tibble(.)
return(t_df)
}
header.true <- function(df) {
names(df) <- as.character(unlist(df[1,]))
df[-1,]
}
data <- data_raw %>% select(-all_of(remove_columns))
fviz_nbclust(data, kmeans, method = "wss") +
geom_vline(xintercept = K, linetype = 2)
km.res <- kmeans(data, K, iter.max = 50, nstart = 20)
tibble(Cluster = seq(1:K),
`Sum of Squares` = km.res$withinss) %>%
niceFormatting(caption = "Within-cluster sum of squares")
evaluate_cluster(km.res$cluster)
# fviz_cluster(km.res, data = data,
#              palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
#              geom = "point",
#              ellipse.type = "convex",
#              ggtheme = theme_bw()
#              )
knitr::opts_chunk$set(
echo = F,
warning = F
)
library(tidyverse)
library(readxl)
library(factoextra)
library(scales)
library(kableExtra)
data_raw <- read_excel('dataset/Planilha_dados_Clusterização_CD_RC_enviada_alterado.xlsx')
data_raw <- data_raw %>% mutate(group = paste0('Group ', group))
remove_columns <- c('record_id', 'group')
K <- 5
paste_matrix <- function(...,sep = " ", collapse = NULL) {
n <- max(sapply(list(...),nrow))
p <- max(sapply(list(...),ncol))
matrix(paste(...,sep = sep,collapse = collapse),n,p)
}
percent <- function(x) paste0("(", lapply(x, as.character), "%)")
addpercentage <- function(df) {
x <- df %>%
prop.table(margin = 1) %>%
addmargins(FUN = list(Total = sum), quiet = TRUE) %>%
round(2) * 100
x[nrow(x),] <- " "
x[-(nrow(x)),] <- lapply(x[-(nrow(x)), ], percent)
y <- matrix(x, nrow = nrow(df) + 1)
df <- df %>%
addmargins(FUN = list(Total = sum), quiet = TRUE)
df_final <- paste_matrix(df, y)
rownames(df_final) <- rownames(df)
colnames(df_final) <- colnames(df)
return(df_final)
}
evaluate_cluster <- function(clusters) {
data <- cbind(data, cluster = clusters) %>%
mutate(cluster = factor(paste0('Cluster ', cluster)))
table(data_raw$group, data$cluster) %>%
addpercentage %>%
as.data.frame %>%
rownames_to_column(var = 'Group') %>%
kbl(align = "c", booktabs = T, digits = 2, format = 'latex',
caption = 'Distribuição dos grupos nos clusters', label = 1) %>%
row_spec(K, hline_after = T) %>%
column_spec(K + 1, border_right = T) %>%
collapse_rows(1, latex_hline = "none") %>%
add_header_above(c(' ' = 1,
setNames(K, 'Cluster'))) %>%
kable_styling(latex_options = c("HOLD_position", "repeat_header")) %>%
print
table(data$cluster, data_raw$group) %>%
addpercentage %>%
as.data.frame %>%
rownames_to_column(var = 'Cluster') %>%
kbl(align = "c", booktabs = T, digits = 2, format = 'latex',
caption = 'Distribuição dos clusters nos grupos', label = 1) %>%
row_spec(K, hline_after = T) %>%
column_spec(K + 1, border_right = T) %>%
collapse_rows(1, latex_hline = "none") %>%
add_header_above(c(' ' = 1,
setNames(K, 'Group'))) %>%
kable_styling(latex_options = c("HOLD_position", "repeat_header")) %>%
print
data %>%
group_by(cluster) %>%
summarise(across(everything(), list(mean = mean))) %>%
ungroup %>%
mutate(across(where(is.numeric), round, 2)) %>%
transpose_df %>%
header.true %>%
mutate(Variable = gsub("\\_.*","", cluster)) %>%
select(Variable, `Cluster 1`, `Cluster 2`, `Cluster 3`, `Cluster 4`, `Cluster 5`) %>%
niceFormatting(caption = 'Médias das variáveis por cluster') %>%
print
}
niceFormatting = function(df, caption="", digits = 2, font_size = NULL, label = 1){
df %>%
kbl(booktabs = T, longtable = T, caption = caption,
digits = digits, format = "latex", label = label) %>%
kable_styling(font_size = font_size,
latex_options = c("striped", "HOLD_position", "repeat_header"))
}
transpose_df <- function(df) {
t_df <- data.table::transpose(df)
colnames(t_df) <- rownames(df)
rownames(t_df) <- colnames(df)
t_df <- t_df %>%
tibble::rownames_to_column(.data = .) %>%
tibble::as_tibble(.)
return(t_df)
}
header.true <- function(df) {
names(df) <- as.character(unlist(df[1,]))
df[-1,]
}
data <- data_raw %>% select(-all_of(remove_columns))
fviz_nbclust(data, kmeans, method = "wss") +
geom_vline(xintercept = K, linetype = 2)
km.res <- kmeans(data, K, iter.max = 50, nstart = 20)
tibble(Cluster = seq(1:K),
`Sum of Squares` = km.res$withinss) %>%
niceFormatting(caption = "Within-cluster sum of squares")
evaluate_cluster(km.res$cluster)
# fviz_cluster(km.res, data = data,
#              palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
#              geom = "point",
#              ellipse.type = "convex",
#              ggtheme = theme_bw()
#              )
data <- data_raw %>%
select(-all_of(remove_columns)) %>%
mutate(across(where(is.numeric), ~ as.numeric(scale(.))))
matrix_distance <- dist(data, method = "euclidean")
dista.hc <- hclust(d = matrix_distance, method = "ward.D")
fviz_dend(dista.hc, cex = 0.5)
evaluate_cluster(cutree(dista.hc, k = K))
data <- data_raw %>%
select(-all_of(remove_columns)) %>%
mutate(across(where(is.numeric), ~ as.numeric(scale(.))))
matrix_distance <- dist(data, method = "euclidean")
dista.hc <- hclust(d = matrix_distance, method = "complete")
fviz_dend(dista.hc, cex = 0.5)
evaluate_cluster(cutree(dista.hc, k = K))
knitr::opts_chunk$set(
echo = F,
warning = F
)
library(tidyverse)
library(readxl)
library(factoextra)
library(scales)
library(kableExtra)
data_raw <- read_excel('dataset/Planilha_dados_Clusterização_CD_RC_enviada_alterado.xlsx')
data_raw <- data_raw %>% mutate(group = paste0('Group ', group))
remove_columns <- c('record_id', 'group')
K <- 4
paste_matrix <- function(...,sep = " ", collapse = NULL) {
n <- max(sapply(list(...),nrow))
p <- max(sapply(list(...),ncol))
matrix(paste(...,sep = sep,collapse = collapse),n,p)
}
percent <- function(x) paste0("(", lapply(x, as.character), "%)")
addpercentage <- function(df) {
x <- df %>%
prop.table(margin = 1) %>%
addmargins(FUN = list(Total = sum), quiet = TRUE) %>%
round(2) * 100
x[nrow(x),] <- " "
x[-(nrow(x)),] <- lapply(x[-(nrow(x)), ], percent)
y <- matrix(x, nrow = nrow(df) + 1)
df <- df %>%
addmargins(FUN = list(Total = sum), quiet = TRUE)
df_final <- paste_matrix(df, y)
rownames(df_final) <- rownames(df)
colnames(df_final) <- colnames(df)
return(df_final)
}
evaluate_cluster <- function(clusters) {
data <- cbind(data, cluster = clusters) %>%
mutate(cluster = factor(paste0('Cluster ', cluster)))
table(data_raw$group, data$cluster) %>%
addpercentage %>%
as.data.frame %>%
rownames_to_column(var = 'Group') %>%
kbl(align = "c", booktabs = T, digits = 2, format = 'latex',
caption = 'Distribuição dos grupos nos clusters', label = 1) %>%
row_spec(K, hline_after = T) %>%
column_spec(K + 1, border_right = T) %>%
collapse_rows(1, latex_hline = "none") %>%
add_header_above(c(' ' = 1,
setNames(K, 'Cluster'))) %>%
kable_styling(latex_options = c("HOLD_position", "repeat_header")) %>%
print
table(data$cluster, data_raw$group) %>%
addpercentage %>%
as.data.frame %>%
rownames_to_column(var = 'Cluster') %>%
kbl(align = "c", booktabs = T, digits = 2, format = 'latex',
caption = 'Distribuição dos clusters nos grupos', label = 1) %>%
row_spec(K, hline_after = T) %>%
column_spec(K + 1, border_right = T) %>%
collapse_rows(1, latex_hline = "none") %>%
add_header_above(c(' ' = 1,
setNames(K, 'Group'))) %>%
kable_styling(latex_options = c("HOLD_position", "repeat_header")) %>%
print
data %>%
group_by(cluster) %>%
summarise(across(everything(), list(mean = mean))) %>%
ungroup %>%
mutate(across(where(is.numeric), round, 2)) %>%
transpose_df %>%
header.true %>%
mutate(Variable = gsub("\\_.*","", cluster)) %>%
select(Variable, `Cluster 1`, `Cluster 2`, `Cluster 3`, `Cluster 4`) %>%
niceFormatting(caption = 'Médias das variáveis por cluster') %>%
print
}
niceFormatting = function(df, caption="", digits = 2, font_size = NULL, label = 1){
df %>%
kbl(booktabs = T, longtable = T, caption = caption,
digits = digits, format = "latex", label = label) %>%
kable_styling(font_size = font_size,
latex_options = c("striped", "HOLD_position", "repeat_header"))
}
transpose_df <- function(df) {
t_df <- data.table::transpose(df)
colnames(t_df) <- rownames(df)
rownames(t_df) <- colnames(df)
t_df <- t_df %>%
tibble::rownames_to_column(.data = .) %>%
tibble::as_tibble(.)
return(t_df)
}
header.true <- function(df) {
names(df) <- as.character(unlist(df[1,]))
df[-1,]
}
data <- data_raw %>% select(-all_of(remove_columns))
fviz_nbclust(data, kmeans, method = "wss") +
geom_vline(xintercept = K, linetype = 2)
km.res <- kmeans(data, K, iter.max = 50, nstart = 20)
tibble(Cluster = seq(1:K),
`Sum of Squares` = km.res$withinss) %>%
niceFormatting(caption = "Within-cluster sum of squares")
evaluate_cluster(km.res$cluster)
# fviz_cluster(km.res, data = data,
#              palette = c("#2E9FDF", "#00AFBB", "#E7B800"),
#              geom = "point",
#              ellipse.type = "convex",
#              ggtheme = theme_bw()
#              )
data <- data_raw %>%
select(-all_of(remove_columns)) %>%
mutate(across(where(is.numeric), ~ as.numeric(scale(.))))
matrix_distance <- dist(data, method = "euclidean")
dista.hc <- hclust(d = matrix_distance, method = "ward.D")
fviz_dend(dista.hc, cex = 0.5)
evaluate_cluster(cutree(dista.hc, k = K))
evaluate_cluster(cutree(dista.hc, k = K))
var(cutree(dista.hc, k = K))
cutree(dista.hc, k = K)
source("C:/Users/p_mat/Documents/GitHub/BDMarcapasso/0-generator.R")
knitr::knit_hooks$set(time_it = local({
now <- NULL
function(before, options) {
if (before) {
# record the current time before each chunk
now <<- Sys.time()
} else {
# calculate the time difference after a chunk
res <- difftime(Sys.time(), now, units = "mins")
# return a character string to show the time
paste("Minutes to run:", round(res, 3))
}
}
}))
knitr::opts_chunk$set(
warning = F,
message = F,
time_it = TRUE
)
k <- params$k # Number of folds for cross validation
grid_size <- params$grid_size # Number of parameter combination to tune on each model
repeats <- params$repeats
RUN_ALL_MODELS <- params$RUN_ALL_MODELS
Hmisc::list.tree(params)
library(tidyverse)
library(yaml)
library(tidymodels)
library(usemodels)
library(vip)
library(bonsai)
library(lightgbm)
library(caret)
library(pROC)
source("aux_functions.R")
predict <- stats::predict
load('dataset/processed_data.RData')
load('dataset/processed_dictionary.RData')
columns_list <- yaml.load_file("./auxiliar/columns_list.yaml")
outcome_column <- params$outcome_column
features_list <- params$features_list
df <- mutate(df, across(where(is.character), as.factor))
dir.create(file.path("./auxiliar/model_selection/hyperparameters/"),
showWarnings = FALSE,
recursive = TRUE)
dir.create(file.path("./auxiliar/model_selection/performance/"),
showWarnings = FALSE,
recursive = TRUE)
cat_features_list = readRDS(sprintf(
"./auxiliar/significant_columns/categorical_%s.rds",
outcome_column
))
num_features_list = readRDS(sprintf(
"./auxiliar/significant_columns/numerical_%s.rds",
outcome_column
))
features_list = c(cat_features_list, num_features_list)
eligible_columns = df_names %>%
filter(momento.aquisicao == 'Admissão t0') %>%
.$variable.name
exception_columns = c('death_intraop', 'death_intraop_1', 'disch_outcomes_t0')
correlated_columns = c('year_procedure_1', # com year_adm_t0
'age_surgery_1', # com age
'admission_t0', # com admission_pre_t0_count
'atb', # com meds_antimicrobianos
'classe_meds_cardio_qtde', # com classe_meds_qtde
'suporte_hemod', # com proced_invasivos_qtde,
'radiografia', # com exames_imagem_qtde
'ecg' # com metodos_graficos_qtde
)
eligible_features = eligible_columns %>%
base::intersect(c(columns_list$categorical_columns, columns_list$numerical_columns)) %>%
setdiff(c(exception_columns, correlated_columns))
features = base::intersect(eligible_features, features_list)
gluedown::md_order(features, seq = TRUE, pad = TRUE)
set.seed(42)
if (outcome_column == 'readmission_30d') {
df_split <- readRDS("./dataset/split_object.rds")
} else {
df_split <- initial_split(df, prop = .7, strata = all_of(outcome_column))
}
df_train <- training(df_split) %>% dplyr::select(all_of(c(features, outcome_column)))
df_test <- testing(df_split) %>% dplyr::select(all_of(c(features, outcome_column)))
df_folds <- vfold_cv(df_train, v = k,
strata = all_of(outcome_column))
xgboost_recipe <-
recipe(formula = sprintf("%s ~ .", outcome_column) %>% as.formula, data = df_train) %>%
step_novel(all_nominal_predictors()) %>%
step_unknown(all_nominal_predictors()) %>%
step_other(all_nominal_predictors(), threshold = 0.05, other = ".merged") %>%
step_dummy(all_nominal_predictors())
xgboost_spec <- boost_tree(
trees = tune(),
min_n = tune(),
tree_depth = tune(),
learn_rate = tune(),
) %>%
set_engine("xgboost",
nthread = 8) %>%
set_mode("classification")
xgboost_grid <- grid_latin_hypercube(
trees(range = c(25L, 150L)),
min_n(range = c(2L, 100L)),
tree_depth(range = c(2L, 15L)),
learn_rate(range = c(-3, -1), trans = log10_trans()),
size = grid_size
)
xgboost_workflow <-
workflow() %>%
add_recipe(xgboost_recipe) %>%
add_model(xgboost_spec)
xgboost_tune <-
xgboost_workflow %>%
tune_grid(resamples = df_folds,
grid = xgboost_grid)
xgboost_tune %>%
show_best("roc_auc")
best_xgboost <- xgboost_tune %>%
select_best("roc_auc")
autoplot(xgboost_tune, metric = "roc_auc")
final_xgboost_workflow <-
xgboost_workflow %>%
finalize_workflow(best_xgboost)
last_xgboost_fit <-
final_xgboost_workflow %>%
last_fit(df_split)
final_xgboost_fit <- extract_workflow(last_xgboost_fit)
xgboost_auc <- validation(final_xgboost_fit, df_test)
extract_vip(final_xgboost_fit, pred_wrapper = predict,
reference_class = "0")
xgboost_parameters <- xgboost_tune %>%
show_best("roc_auc", n = 1) %>%
select(trees, min_n, tree_depth, learn_rate, loss_reduction) %>%
as.list
source("C:/Users/p_mat/Documents/GitHub/BDMarcapasso/0-generator.R")
source("C:/Users/p_mat/Documents/GitHub/BDMarcapasso/0-generator.R")
install.packages('glmnet')
source("C:/Users/p_mat/Documents/GitHub/BDMarcapasso/0-generator.R")
install.packages('randomForest', 'randomForest')
source("C:/Users/p_mat/Documents/GitHub/BDMarcapasso/0-generator.R")
source("C:/Users/p_mat/Documents/GitHub/BDMarcapasso/0-generator.R")
